{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([32, 64, 128, 256, 512], [32, 64, 128, 256, 512], [512, 256, 128, 64, 32])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE\n",
    "'''\n",
    "input img tensor should look like `[B,3, 64, 64]`\n",
    "'''\n",
    "\n",
    "# CONSTANTS\n",
    "IN_CHANNELS = 3\n",
    "LATENT_DIM = 128 # temp\n",
    "HIDDEN_DIM = [32, 64, 128, 256, 512]\n",
    "ENCODER_HIDDEN_DIM = HIDDEN_DIM\n",
    "DECODER_HIDDEN_DIM = HIDDEN_DIM.copy()\n",
    "DECODER_HIDDEN_DIM.reverse()\n",
    "\n",
    "DEVICE = torch.device('mps')\n",
    "\n",
    "HIDDEN_DIM, ENCODER_HIDDEN_DIM, DECODER_HIDDEN_DIM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_modules = []\n",
    "in_channels = IN_CHANNELS\n",
    "\n",
    "for h_dim in ENCODER_HIDDEN_DIM:\n",
    "    encoder_modules.append(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=h_dim,\n",
    "                      kernel_size=3, stride=2, padding= 1),\n",
    "            nn.BatchNorm2d(h_dim),\n",
    "            nn.LeakyReLU())\n",
    "    )\n",
    "    in_channels = h_dim\n",
    "\n",
    "encoder = nn.Sequential(*encoder_modules)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean and Variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_mu = nn.Linear(HIDDEN_DIM[-1]*4, LATENT_DIM)\n",
    "fc_var = nn.Linear(HIDDEN_DIM[-1]*4, LATENT_DIM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_modules = []\n",
    "\n",
    "decoder_input = nn.Linear(LATENT_DIM, HIDDEN_DIM[-1]*4)\n",
    "\n",
    "for i in range(len(DECODER_HIDDEN_DIM) - 1):\n",
    "    decoder_modules.append(\n",
    "        nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=DECODER_HIDDEN_DIM[i],\n",
    "                               out_channels=DECODER_HIDDEN_DIM[i+1],\n",
    "                               kernel_size=3,\n",
    "                               stride=2,\n",
    "                               padding=1,\n",
    "                               output_padding=1),\n",
    "            nn.BatchNorm2d(DECODER_HIDDEN_DIM[i + 1]),\n",
    "            nn.LeakyReLU())\n",
    "    )\n",
    "\n",
    "decoder = nn.Sequential(*decoder_modules)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_layer = nn.Sequential(\n",
    "    nn.ConvTranspose2d(in_channels=DECODER_HIDDEN_DIM[-1],\n",
    "                       out_channels=DECODER_HIDDEN_DIM[-1],\n",
    "                       kernel_size=3,\n",
    "                       stride=2,\n",
    "                       padding=1,\n",
    "                       output_padding=1),\n",
    "    nn.BatchNorm2d(DECODER_HIDDEN_DIM[-1]),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(in_channels=DECODER_HIDDEN_DIM[-1],\n",
    "              out_channels=3,\n",
    "              kernel_size=3,\n",
    "              padding=1),\n",
    "    nn.Tanh()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(input:torch.Tensor) -> List[torch.Tensor]:\n",
    "\n",
    "    result = encoder(input)\n",
    "    result = torch.flatten(result, start_dim=1)\n",
    "\n",
    "    mu = fc_mu(result)\n",
    "    log_var = fc_var(result)\n",
    "\n",
    "    return [mu, log_var]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ―――――――――――――――――――――――――――――― Test  ―――――――――――――――――――――――――――――――――――"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512, 2, 2]) torch.Size([32, 2048])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.ones([32, 3, 64, 64])\n",
    "encoded_tensor = encoder(input_tensor)\n",
    "print(encoded_tensor.shape, encoded_tensor.flatten(1).shape)\n",
    "# print(fc_mu.weight.shape)\n",
    "# encode(input_tensor)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ―――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(z: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "    result = decoder_input(z)\n",
    "    result = result.view(-1, 512, 2, 2)\n",
    "    result = decoder(result)\n",
    "    result = final_layer(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparameterize(mu: torch.Tensor, log_var: torch.Tensor):\n",
    "    '''\n",
    "    Monte Carlo -> M = 1\n",
    "    '''\n",
    "    std = torch.exp(0.5 * log_var)\n",
    "    eps = torch.randn_like(std) # log_var이랑 동일한 shape으로 noise ~ N(0,1)에서 sampling -> 1번만 샘플링했음.\n",
    "    # 만약 여러번 샘플링 한다면\n",
    "    '''\n",
    "    (eps1 * std + mu) + (eps2 * std + mu) + (eps3 * std + mu) + (eps4 * std + mu) + ... + (epsM * std + mu) \n",
    "    = (eps1 + ... + epsM)/M * std + mu\n",
    "    '''\n",
    "    return eps * std + mu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(input:torch.Tensor)-> List[torch.Tensor]:\n",
    "    mu, log_var = encode(input)\n",
    "    z = reparameterize(mu, log_var)\n",
    "    return [decode(z), input, mu, log_var]\n",
    "\n",
    "## Quesion was: encoder의 파라미터 phi랑 decoder 파라미터 pi가 있는데, 한번에 backpropagate해도 되는건가.. 싶었는데 될것같긴한데, 일단 cs330-12듣고 다시 이어서 하기."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ―――――――――――――――――――――――――――――― Test  ―――――――――――――――――――――――――――――――――――"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Encode =====\n",
      "encoded_tensor:  torch.Size([32, 512, 2, 2])\n",
      "\n",
      "1. Flatten =====\n",
      "flatten_tensor:  torch.Size([32, 2048])\n",
      "\n",
      "3. Mean and log(Var) =====\n",
      "mu.weights:  torch.Size([128, 2048])\n",
      "var.weights:  torch.Size([128, 2048])\n",
      "mu:  torch.Size([32, 128])\n",
      "var:  torch.Size([32, 128])\n",
      "\n",
      "4. ReParameterize =====\n",
      "latent_var(z):  torch.Size([32, 128])\n",
      "\n",
      "5. Decoder Input (FC) =====\n",
      "latent_input:  torch.Size([32, 2048])\n",
      "decoder_input_linear:  torch.Size([2048, 128])\n",
      "\n",
      "6. Reshape Decoder Input =====\n",
      "latent_input (reshape):  torch.Size([32, 512, 2, 2])\n",
      "\n",
      "7. Decode =====\n",
      "decoded_tensor:  torch.Size([32, 32, 32, 32])\n",
      "\n",
      "8. Final Layer =====\n",
      "out:  torch.Size([32, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "## Testing Forward pass\n",
    "input_tensor = torch.ones([32, 3, 64, 64]) # [B, C, H, W]\n",
    "\n",
    "# 1. Encode\n",
    "print('\\n1. Encode =====')\n",
    "encoded_tensor = encoder(input_tensor)\n",
    "print('encoded_tensor: ', encoded_tensor.shape)\n",
    "\n",
    "# 2. Flatten\n",
    "print('\\n1. Flatten =====')\n",
    "flatten_tensor = encoded_tensor.flatten(start_dim=1)\n",
    "print('flatten_tensor: ',flatten_tensor.shape)\n",
    "\n",
    "# 3. Mean and log(var)\n",
    "print('\\n3. Mean and log(Var) =====')\n",
    "mu = fc_mu(flatten_tensor)\n",
    "log_var = fc_var(flatten_tensor)\n",
    "print('mu.weights: ', fc_mu.weight.shape)\n",
    "print('var.weights: ', fc_var.weight.shape)\n",
    "print('mu: ', mu.shape)\n",
    "print('var: ', log_var.shape)\n",
    "\n",
    "# 4. re-parameterize\n",
    "print('\\n4. ReParameterize =====')\n",
    "latent_var = reparameterize(mu,log_var)\n",
    "print('latent_var(z): ', latent_var.shape)\n",
    "\n",
    "# 5. decoder input\n",
    "print('\\n5. Decoder Input (FC) =====')\n",
    "latent_input = decoder_input(latent_var)\n",
    "print('latent_input: ',latent_input.shape)\n",
    "print('decoder_input_linear: ',decoder_input.weight.shape)\n",
    "\n",
    "# 6. Reshape Decoder Input\n",
    "print('\\n6. Reshape Decoder Input =====')\n",
    "latent_input = latent_input.view(-1, 512, 2, 2)\n",
    "print('latent_input (reshape): ', latent_input.shape)\n",
    "\n",
    "# 7. Decode\n",
    "print('\\n7. Decode =====')\n",
    "decoded_tensor = decoder(latent_input)\n",
    "# print(decoder.named_parameters)\n",
    "print('decoded_tensor: ',decoded_tensor.shape)\n",
    "\n",
    "# 8. Final Layer\n",
    "print('\\n8. Final Layer =====')\n",
    "out = final_layer(decoded_tensor)\n",
    "print('out: ', out.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ―――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(*args, **kwargs) -> dict:\n",
    "\n",
    "    recons = args[0]\n",
    "    input = args[1]\n",
    "    mu = args[2]\n",
    "    log_var = args[3]\n",
    "\n",
    "    kld_weight = kwargs['M_N'] #Account for minibatch samples from the dataset.\n",
    "\n",
    "    recons_loss = F.mse_loss(recons, input) # EXP_z~q(z|x)[log(p(x|z))] - KLD(q(z|x) || p(z))\n",
    "\n",
    "    kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim =1 ), dim = 0) # Closed-form of KLD of q(z|x) = N(mu, var) and p(z) = N(0,1)\n",
    "    \n",
    "    loss= recons_loss + kld_weight * kld_loss\n",
    "\n",
    "    return {'loss': loss, 'Reconstruction_Loss':recons_loss.detach(), 'KLD':-kld_loss.detach()}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(num_samples:int,\n",
    "           **kwargs):\n",
    "    # since KL loss encouraged the encoder to map input x to latent distribution q(z|x) that closely approximates the Standard Normal Dist.\n",
    "    z = torch.randn(num_samples, LATENT_DIM) \n",
    "\n",
    "    z = z.to(DEVICE)\n",
    "    samples = decode(z)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(x:torch.Tensor) -> torch.Tensor:\n",
    "    return forward(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'a':0,'b':1,'c':3}\n",
    "print({f'{key}`': val for key, val in a.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
