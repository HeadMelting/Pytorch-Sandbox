{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. PyTorch Fundamentals\n",
    "\n",
    "Resource notebook : https://www.learnpytorch.io/00_pytorch_fundamentals\n",
    "\n",
    "### Lectures\n",
    "- 12. Getting set up to write pytorch code \n",
    "~\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyunsukim/miniconda3/envs/python-study/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(torch.backends.mps.is_available())\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Tensors\n",
    "\n",
    "### Creating tensors\n",
    "\n",
    "Pytorch tensors are created using [`torch.Tensor()`](https://pytorch.org/docs/stable/tensors.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "MATRIX = torch.tensor([[7, 8],\n",
    "                       [9,10]])\n",
    "\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [4, 5, 6]],\n",
       "\n",
       "        [[2, 3, 4],\n",
       "         [3, 6, 2],\n",
       "         [4, 5, 6]],\n",
       "\n",
       "        [[4, 5, 3],\n",
       "         [3, 6, 9],\n",
       "         [4, 5, 6]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [4, 5, 6]],\n",
    "                        [[2, 3, 4],\n",
    "                        [3, 6, 2],\n",
    "                        [4, 5, 6]],\n",
    "                        [[4, 5, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [4, 5, 6]]])\n",
    "\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [3, 6, 9],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 4],\n",
       "        [3, 6, 2],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarise\n",
    "\n",
    "scalar: 0dim, lowercase (ex : a)\n",
    "vector :1dim, lowercae (ex: y)\n",
    "matrix: 2dim, Uppercase (ex: Q)\n",
    "Tensor: can be any number, Uppercase (ex: T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random tensors\n",
    "\n",
    "Why Random Tensors?\n",
    "\n",
    "\n",
    "Random tensors are important because the way many neraul networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
    "\n",
    "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3311, 0.5085, 0.0885, 0.6580],\n",
       "        [0.3865, 0.3699, 0.2889, 0.1567],\n",
       "        [0.6437, 0.9552, 0.7145, 0.9822]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of shape (3, 4)\n",
    "random_tensor = torch.rand(3, 4)\n",
    "\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with similar shpae to an iamge\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3,)) # height, width, color channel\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3,4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros*random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3,4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype, random_tensor.dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Range\n",
    "#### Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m3/gc3jv3513p9b_6y82p_46vmw0000gn/T/ipykernel_72030/4106555132.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  torch.range(0, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use torch.range()\n",
    "torch.range(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_ten = torch.arange(1,11)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 5, 7, 9])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(start=1, end=10, step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10]), torch.Size([10]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Tensors Like\n",
    "one_to_ten_like = torch.zeros_like(input=one_to_ten)\n",
    "one_to_ten_like.shape, one_to_ten.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                                dtype=None, # What data type is the tensor( e.g. float32, float16, int8)\n",
    "                                device='cpu', # 디바이스\n",
    "                                requires_grad=False) # operation gradients\n",
    "\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision in computing\n",
    "\n",
    "in CS, the precision of a numerical quantity is a measore of the detail in which the quantity is expressed. \n",
    "Single precision 32bits in Computuer memeory (32 bit float -> single precision , 16bit -> half precision)\n",
    "\n",
    "\n",
    "## Tensor Datatypes\n",
    "**Note:** Tensor datatypes is one of the 3 big errors\n",
    "1. Tensors not right datatype\n",
    "2. not right shape\n",
    "3. not right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2314453125, 1.2312312126159668)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_scalar = torch.tensor(1.231231231,dtype=torch.float16)\n",
    "float_32_scalar = torch.tensor(1.231231231,dtype=torch.float32)\n",
    "float_16_scalar.item(), float_32_scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3, 6, 9], dtype=torch.long)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor * int_32_tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting information from tensors\n",
    "\n",
    "1. torch.dtype for data type\n",
    "2. torch.shape for shape\n",
    "3. torch.device for device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8546, -1.4674,  1.8471, -1.6603],\n",
       "        [-1.7010,  2.1963,  1.4835, -0.1373],\n",
       "        [-0.2410, -1.0774, -0.1860,  0.1734]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = torch.randn(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.Size([3, 4]), device(type='cpu'))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.dtype, some_tensor.shape, some_tensor.device\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Tensors (tensor operations)\n",
    "\n",
    "Tensor operations include:\n",
    "* Addition\n",
    "& Subtraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([101, 102, 103])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor and add 100\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply tensor by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substract 10\n",
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100, 200, 300])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTroch in-built function\n",
    "tensor.mul(10)\n",
    "tensor.mul_(10)\n",
    "torch.mul(tensor, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n",
    "\n",
    "Two main ways of performing multiplication in NN and eep learning:\n",
    "1. Element-wise multiplication\n",
    "2. Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100, 400, 900])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element wise Multiplication\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1400)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix Mutliplication\n",
    "torch.matmul(tensor,tensor)\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix Multiplication by hand\n",
    "1 * 1 + 2 * 2 + 3* 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 394 µs, sys: 406 µs, total: 800 µs\n",
      "Wall time: 454 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1400)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 83 µs, sys: 29 µs, total: 112 µs\n",
      "Wall time: 111 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1400)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "torch.matmul(tensor,tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One of the most common erros in deep learning: SHAPE ERROR\n",
    "\n",
    "Two main Rules that performing matrix multiplication needs to satisfy:\n",
    "1. The **inner dimensions** must match:\n",
    "* `(3,2) @ (3,2)` won't work\n",
    "* `(2,3) @ (3,2)` will work\n",
    "* `(3,2) @ (2,3)` will work\n",
    "\n",
    "2. The resulting matrix has the shape of the **outer dimensions**:\n",
    "* `(2,3) @ (3,2) : (2,2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5916, 0.1580, 0.7611, 0.4703, 0.1640, 0.7477, 0.3873, 0.7369, 0.1646,\n",
       "         0.3878],\n",
       "        [0.3247, 0.2799, 0.8643, 0.8639, 0.2622, 0.9543, 0.5065, 0.6452, 0.2285,\n",
       "         0.8194],\n",
       "        [0.6553, 0.3065, 1.1469, 0.9332, 0.2989, 1.1984, 0.6291, 0.9801, 0.2763,\n",
       "         0.8423]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.rand(3,2),torch.rand(2,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27,  30,  33],\n",
       "        [ 61,  68,  75],\n",
       "        [ 95, 106, 117]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shapes for matrix Multiplication\n",
    "\n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                        [3, 4],\n",
    "                        [5, 6]])\n",
    "\n",
    "tensor_B = torch.tensor([[7,10],\n",
    "                        [8,11],\n",
    "                        [9,12]])\n",
    "\n",
    "# torch.mm() # torch.mm is the same as torch.matmul (it's an alias for writing less code)\n",
    "torch.mm(tensor_A, tensor_B.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.size(), tensor_B.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix our tensor shape issues, we can manipulate the shape of one of our tensors using a **transpose**.\n",
    "\n",
    "A transpose switches the axes or diemensions of a given tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8,  9],\n",
       "        [10, 11, 12]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m3/gc3jv3513p9b_6y82p_46vmw0000gn/T/ipykernel_72030/1796962038.py:7: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525498485/work/aten/src/ATen/native/TensorShape.cpp:3281.)\n",
      "  test.shape, test.T[0], test.permute(2,1,0)[0], test.view(5,4,3)[0],test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4, 5]),\n",
       " tensor([[ 1, 21, 41],\n",
       "         [ 6, 26, 46],\n",
       "         [11, 31, 51],\n",
       "         [16, 36, 56]]),\n",
       " tensor([[ 1, 21, 41],\n",
       "         [ 6, 26, 46],\n",
       "         [11, 31, 51],\n",
       "         [16, 36, 56]]),\n",
       " tensor([[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9],\n",
       "         [10, 11, 12]]),\n",
       " tensor([[[ 1,  2,  3,  4,  5],\n",
       "          [ 6,  7,  8,  9, 10],\n",
       "          [11, 12, 13, 14, 15],\n",
       "          [16, 17, 18, 19, 20]],\n",
       " \n",
       "         [[21, 22, 23, 24, 25],\n",
       "          [26, 27, 28, 29, 30],\n",
       "          [31, 32, 33, 34, 35],\n",
       "          [36, 37, 38, 39, 40]],\n",
       " \n",
       "         [[41, 42, 43, 44, 45],\n",
       "          [46, 47, 48, 49, 50],\n",
       "          [51, 52, 53, 54, 55],\n",
       "          [56, 57, 58, 59, 60]]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## SS\n",
    "test = torch.arange(1,61)\n",
    "test = test.view(3,4,5)\n",
    "\n",
    "\n",
    "# Permute은 element 순서 자체도 바뀜. 하지만 View는 유지\n",
    "test.shape, test.T[0], test.permute(2,1,0)[0], test.view(5,4,3)[0],test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the min, max, mean, sum, etc (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor\n",
    "x = torch.arange(1, 100, 10)\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(1))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the min\n",
    "torch.min(x), x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(91), tensor(91))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the max\n",
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 266 µs, sys: 243 µs, total: 509 µs\n",
      "Wall time: 312 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(46., dtype=torch.float16)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Find the mean\n",
    "# torch.mean(x, dtype=torch.float32)\n",
    "# torch.mean(x.type(torch.float32))\n",
    "x.type(torch.float16).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(460), tensor(460))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the sum\n",
    "torch.sum(x), x.sum()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the positional min and max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in the tensor that has the minimum value with argmin() -> returns index position of target\n",
    "x.argmin()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the mosition in tensor that hs the maximum value with argmax()\n",
    "x.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(91)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "* Reshaping - reshapes an input tensors to a defined shape\n",
    "* View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
    "* Squeeze - remove all `1` dimensions from a tensor\n",
    "* unSqueeze - add a `1` dim to a target tensor\n",
    "* permute - return a view of the input with dimensions permuted (sapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a tensor\n",
    "x = torch.arange(1., 10.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1, 9)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view -> same memery as the original input (x)\n",
    "z = x.view(1, 9)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z는 x의 view라서 메모리를 공유함\n",
    "z[:, 0] = 5\n",
    "z, x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5., 2., 3., 4., 5., 6., 7., 8., 9.]],\n",
       "\n",
       "        [[5., 2., 3., 4., 5., 6., 7., 8., 9.]],\n",
       "\n",
       "        [[5., 2., 3., 4., 5., 6., 7., 8., 9.]],\n",
       "\n",
       "        [[5., 2., 3., 4., 5., 6., 7., 8., 9.]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x.unsqueeze(0),x.unsqueeze(0),x.unsqueeze(0),x.unsqueeze(0),], dim=0)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 1, 9]),\n",
       " tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " torch.Size([4, 9]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# squeeze -> Same Memory\n",
    "x_squeezed = x_stacked.squeeze()\n",
    "x_stacked.shape,x_stacked.squeeze(), x_stacked.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([[[1., 2., 3., 4., 5., 6., 7., 8., 9.]],\n",
       " \n",
       "         [[5., 2., 3., 4., 5., 6., 7., 8., 9.]],\n",
       " \n",
       "         [[5., 2., 3., 4., 5., 6., 7., 8., 9.]],\n",
       " \n",
       "         [[5., 2., 3., 4., 5., 6., 7., 8., 9.]]]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_squeezed[0][0] = 1\n",
    "x_squeezed, x_stacked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape:torch.Size([224, 224, 3])\n",
      "New Shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute - Same memory\n",
    "x_orginial = torch.randn(size=(224, 224, 3)) #[height, width, colour_channels(RGB)]\n",
    "\n",
    "# Permute the original tensor to rearrange the axis (or dim) order\n",
    "x_permuted = x_orginial.permute(2, 0, 1) # shifts axis 0 -> 1, 1 -> 2, 2 -> 0\n",
    "\n",
    "print(f'Previous shape:{x_orginial.shape}')\n",
    "print(f'New Shape: {x_permuted.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(123.), tensor(123.))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_orginial[0,0,0] = 123\n",
    "x_orginial[0,0,0], x_permuted[0,0,0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing\n",
    "    | Selecting data from tensors\n",
    "\n",
    "indexing with pytorch is similar to indexing with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Createa a tensor\n",
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outer bracket\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), tensor([1, 2, 3]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# middle Bracket (dim = 1)\n",
    "x[0][0], x[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inner bracket (last dim)\n",
    "x[0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can use \":\" to select all of target dimension\n",
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all Values of 0th and 1st dimensions but only index 1 of 2nd dimension\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of the 0 dimension but only the 1 index value of 1st and 2nd dimension\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch tensors & Numpy\n",
    "\n",
    "Numpy is a popular scientific python numerical computing library.\n",
    "\n",
    "And because of this, pytorch has functionality to interact with it\n",
    "\n",
    "* Data in NumPy, want in PyTorch tensor -> `torch.from_numpy(ndarray)`\n",
    "* Pytorch tensor -> NumPy -> `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([0., 2., 3., 4., 5., 6., 7.], dtype=torch.float64),\n",
       " tensor([3., 2., 3., 4., 5., 6., 7.], dtype=torch.float64),\n",
       " tensor([32.,  2.,  3.,  4.,  5.,  6.,  7.]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy Array to tensor\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Float64 -> default NumPy Data type\n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.tensor(array)\n",
    "tensor_f_n = torch.from_numpy(array)\n",
    "tensor_f_n_32 = torch.from_numpy(array).type(torch.float32)\n",
    "\n",
    "tensor[0] = 0\n",
    "tensor_f_n[0] = 3\n",
    "tensor_f_n_32[0] = 32\n",
    "\n",
    "# from numpy -> orignial 과 동일한 메모리이지만, dtype을 바꿀 경우 새로 만듬.\n",
    "\n",
    "array, tensor, tensor_f_n,tensor_f_n_32\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float64, torch.float32, dtype('float64'), torch.float64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_f_n.dtype, tensor_f_n_32.dtype, array.dtype, tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 4. 5. 6. 7. 8. 9.] tensor([0., 2., 3., 4., 5., 6., 7.], dtype=torch.float64) tensor([5., 4., 5., 6., 7., 8., 9.], dtype=torch.float64) tensor([32.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "[5. 4. 5. 6. 7. 8. 9.] tensor([0., 2., 3., 4., 5., 6., 7.], dtype=torch.float64) tensor([ 7.,  6.,  7.,  8.,  9., 10., 11.], dtype=torch.float64) tensor([32.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Chage the value of array, what will this do to 'tensor'?\n",
    "\n",
    "array = array + 1\n",
    "print(array, tensor, tensor_f_n, tensor_f_n_32)\n",
    "\n",
    "tensor_f_n = tensor_f_n + 2\n",
    "print(array, tensor, tensor_f_n, tensor_f_n_32)\n",
    "\n",
    "print(array is tensor_f_n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducbility (trying to take random out of random)\n",
    "\n",
    "[pytorch.manual_seed](https://pytorch.org/docs/stable/notes/randomness.html)\n",
    "\n",
    "In short how a neural network learns:\n",
    "\n",
    "`start with random numbers -> tensor operations -> update random num to tray and make them better representataions of the data -> again -> ... `\n",
    "\n",
    "To reduce the randomness in NN and PyTorch comes the concept of a **random seed**.\n",
    "\n",
    "Essentially what the random seed does is 'flavour' the randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4724, 0.3656, 0.3799],\n",
       "        [0.9529, 0.0132, 0.8503],\n",
       "        [0.2219, 0.7998, 0.9310]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실행시킬때 마다 새로운 랜덤 숫자를 줌...\n",
    "torch.rand(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7667, -1.2694,  1.3980,  1.4200],\n",
      "        [ 0.1936, -1.4756, -0.6068, -1.9233],\n",
      "        [ 1.0280,  1.6009, -0.8622,  0.9882]])\n",
      "tensor([[ 0.6090, -0.5888, -0.5132,  2.6157],\n",
      "        [-0.6621, -1.1979, -0.0706,  0.7310],\n",
      "        [ 0.4848,  0.2265, -0.0631, -0.2832]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# Create two random tensors\n",
    "random_tensor_A = torch.randn(3, 4)\n",
    "random_tensor_B = torch.randn(3, 4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_A == random_tensor_B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2919, 0.2857, 0.4021, 0.4645],\n",
      "        [0.9503, 0.2564, 0.6645, 0.8609],\n",
      "        [0.3538, 0.3347, 0.7285, 0.5794]])\n",
      "tensor([[0.2919, 0.2857, 0.4021, 0.4645],\n",
      "        [0.9503, 0.2564, 0.6645, 0.8609],\n",
      "        [0.3538, 0.3347, 0.7285, 0.5794]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Let's make some random but reproducible tensors\n",
    "import torch\n",
    "\n",
    "# Set the random seed\n",
    "RANDOM_SEED = 77\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED) # Rand 호출 전에 다시 seed를 또 콜해주면 동일한 tensor가 만들어지네요..!\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C == random_tensor_D)\n",
    "print(random_tensor_C is random_tensor_D)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Tensors and PyTorch objects on the GPUs (and making faster computataions)\n",
    "\n",
    "GPUs= Faster Computation on numbers, thanks to CUDA + NVIDIA hardware + PyTorch "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Getting a GPU\n",
    "\n",
    "1. Easiest - use Google Colab for free GPU\n",
    "2. Use your own GPU - takes a little bit of setup and investment.\n",
    "3. Use Cloud Computing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Check for GPU access with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.backends.mps.is_available()\n",
    "# torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], device='mps:0')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with that been said\n",
    "# Count number of devices\n",
    "\n",
    "a = torch.ones(1,device=torch.device('mps:3'))\n",
    "a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Putting tensors (and models) on the GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor (default on the CPU)\n",
    "tensor = torch.tensor([1,2,3], device='cpu')\n",
    "\n",
    "# Tensor Not on GPU\n",
    "print(tensor, tensor.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='mps:0')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move tensor to GPU (if available\n",
    "\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Tensors Back to the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# If tensor is on GPU, can't transform it to NumPy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tensor_on_gpu\u001b[39m.\u001b[39;49mnumpy()\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# If tensor is on GPU, can't transform it to NumPy\n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 3, 4]), tensor([1, 2, 4], device='mps:0'))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_on_cpu[1] = 3\n",
    "tensor_on_cpu, tensor_on_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 4], device='mps:0'), tensor([1, 2, 3]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu[2] = 4\n",
    "tensor_on_gpu, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 4], device='mps:0')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise and Extra-curriulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
